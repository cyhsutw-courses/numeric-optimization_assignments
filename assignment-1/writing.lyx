#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language chinese-traditional
\language_package default
\inputencoding euc-tw
\fontencoding global
\font_roman Kozuka Gothic Pro
\font_sans Source Han Sans TC
\font_typewriter default
\font_math auto
\font_default_family default
\use_non_tex_fonts true
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format pdf4
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\topmargin 5pheight%
\bottommargin 5pheight%
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Numeric Optimization - Assignment #01
\end_layout

\begin_layout Author
103062512 徐丞裕
\end_layout

\begin_layout Enumerate
Solution:
\end_layout

\begin_deeper
\begin_layout Enumerate
Approximation of 
\begin_inset Formula $f(x)$
\end_inset

 at point 
\begin_inset Formula $x_{k}$
\end_inset

 using second order Taylor series:
\end_layout

\begin_layout Enumerate
Find optimal point of 
\begin_inset Formula $\tilde{f}$
\end_inset

:
\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset Formula 
\begin{multline*}
\begin{array}{ccc}
\tilde{f}(x) & = & \frac{f^{(2)}(x_{k})}{2!}((x-x_{k})^{2}+2\frac{f^{(1)}(x_{k})}{f^{(2)}(x_{k})}(x-x_{k})+(\frac{f^{(1)}(x_{k})}{f^{(2)}(x_{k})})^{2})+(f(x_{k})-\frac{(f^{(1)}(x_{k}))^{2}}{2f^{(2)}(x_{k})})\\
\tilde{f}(x) & = & \frac{f^{(2)}(x_{k})}{2!}((x-x_{k})+\frac{f^{(1)}(x_{k})}{f^{(2)}(x_{k})})^{2}+(f(x_{k})-\frac{(f^{(1)}(x_{k}))^{2}}{2f^{(2)}(x_{k})})\\
x^{*} & = & x_{k}-\frac{f^{(1)}(x_{k})}{f^{(2)}(x_{k})}
\end{array}
\end{multline*}

\end_inset


\end_layout

\end_deeper
\begin_layout Enumerate
Apply update rule of Newton's method:
\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset Formula 
\[
\begin{array}{ccc}
x_{k+1} & = & x_{k}-H^{-1}g\\
x_{k+1} & = & x_{k}-(f^{(2)}(x_{k}))^{-1}f^{(1)}(x_{k})\\
x_{k+1} & = & x_{k}-\frac{f^{(2)}(x_{k})}{f^{(1)}(x_{k})}
\end{array}
\]

\end_inset


\end_layout

\end_deeper
\end_deeper
\begin_layout Enumerate
Solution:
\end_layout

\begin_deeper
\begin_layout Enumerate
With small 
\begin_inset Formula $\alpha$
\end_inset

, the interpolation method is quite similar to Newton's method which also
 derive a quadratic model near 
\begin_inset Formula $x_{k}$
\end_inset

.
 To show this, please see the graph below:
\end_layout

\begin_deeper
\begin_layout Standard
Target function: 
\begin_inset Formula $f(x)=x^{4}-2x^{2}+3x^{2}-4x+5$
\end_inset


\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename problem_2_a/problem_2_a_approx.eps
	width 60page%

\end_inset


\end_layout

\begin_layout Standard
As the behavior of interpolation method is quite similar to the Newton's
 method with 
\begin_inset Formula $\alpha$
\end_inset

 sufficiently small, one can fail the interpolation method with an example
 that will make Newton's method to fail.
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Standard
To fail Newton's method, consider the following function:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
w(x)=\begin{cases}
\begin{array}{c}
\frac{2}{3}(-x)^{\frac{3}{2}}\\
0\\
\frac{2}{3}x{}^{\frac{3}{2}}
\end{array} & \begin{array}{c}
x<0\\
x=0\\
x>0
\end{array}\end{cases}
\]

\end_inset


\end_layout

\begin_layout Standard
For 
\begin_inset Formula $w(x)$
\end_inset

, the update rule of Newton's method is:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
x_{k+1}=\begin{cases}
\begin{array}{c}
x_{k}-2\frac{x^{\frac{1}{2}}}{x^{-\frac{1}{2}}}\\
x_{k}+2\frac{(-x)^{\frac{1}{2}}}{(-x)^{-\frac{1}{2}}}
\end{array} & \begin{array}{c}
x>0\\
x<0
\end{array}\end{cases}
\]

\end_inset


\end_layout

\begin_layout Standard
By choosing 
\begin_inset Formula $x_{0}=3$
\end_inset

, we have:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\begin{array}{ccc}
x_{1} & = & 3-6\\
x_{2} & = & -3+6\\
 & \vdots
\end{array}
\]

\end_inset


\end_layout

\begin_layout Standard
which will not make Newton's method converge obviously.
\end_layout

\end_deeper
\begin_layout Enumerate
Pros & cons:
\end_layout

\begin_deeper
\begin_layout Enumerate
Pros of interpolation method compared to Newton's method:
\end_layout

\begin_deeper
\begin_layout Enumerate
Does not require any information about derivatives.
\end_layout

\begin_layout Enumerate
Has behavior of Newton's method when 
\begin_inset Formula $\alpha$
\end_inset

 is sufficiently small.
\end_layout

\end_deeper
\begin_layout Enumerate
Cons of interpolation method compared to Newton's method:
\end_layout

\begin_deeper
\begin_layout Enumerate
Solving the linear system may be more and more expensive as the dimension
 
\begin_inset Formula $x_{k}$
\end_inset

 grows.
\end_layout

\end_deeper
\end_deeper
\begin_layout Enumerate
Let the cubic function used for approximating 
\begin_inset Formula $f(x)$
\end_inset

 be 
\begin_inset Formula $n(x)=ax^{3}+bx^{2}+cx+d$
\end_inset

, we can obtain 
\begin_inset Formula $a$
\end_inset

, 
\begin_inset Formula $b$
\end_inset

, 
\begin_inset Formula $c$
\end_inset

, and 
\begin_inset Formula $d$
\end_inset

 by solving the following linear system:
\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset Formula 
\[
\left[\begin{array}{cccc}
x_{1}^{3} & x_{1}^{2} & x_{1} & 1\\
3x_{1}^{2} & 2x_{1} & 1 & 0\\
x_{2}^{3} & x_{2}^{2} & x_{2} & 1\\
3x_{2}^{2} & 2x_{2} & 1 & 0
\end{array}\right]\left[\begin{array}{c}
a\\
b\\
c\\
d
\end{array}\right]=\left[\begin{array}{c}
f(x_{1})\\
f'(x_{1})\\
f(x_{2})\\
f'(x_{2})
\end{array}\right]
\]

\end_inset


\end_layout

\end_deeper
\end_deeper
\begin_layout Enumerate
Solution:
\end_layout

\begin_deeper
\begin_layout Enumerate
Gradient 
\begin_inset Formula $g$
\end_inset

 and Hessian matrix 
\begin_inset Formula $H$
\end_inset

 of 
\begin_inset Formula $f$
\end_inset

:
\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset Formula 
\[
g=\left(\begin{array}{c}
\frac{\partial f}{\partial x}\\
\frac{\partial f}{\partial y}
\end{array}\right)=\left(\begin{array}{c}
x\\
9y
\end{array}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
H=\left[\begin{array}{cc}
\frac{\partial^{2}f}{\partial^{2}x} & \frac{\partial^{2}f}{\partial x\partial y}\\
\frac{\partial^{2}f}{\partial y\partial x} & \frac{\partial^{2}f}{\partial^{2}x}
\end{array}\right]=\left[\begin{array}{cc}
1 & 0\\
0 & 9
\end{array}\right]
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Enumerate
Convergence criteria: 
\begin_inset Formula $\left\Vert x_{k+1}-x_{k}\right\Vert <10^{-4}$
\end_inset

 
\end_layout

\begin_deeper
\begin_layout Enumerate
Steepest descent: 46 iterations.
\end_layout

\begin_layout Enumerate
Newton's method: 1 iteration.
\end_layout

\end_deeper
\begin_layout Enumerate
Traces of steepest descent and Newton's method:
\end_layout

\begin_deeper
\begin_layout Standard
\align center
\begin_inset Graphics
	filename problem_3_b_c/problem_3.eps
	width 60page%

\end_inset


\end_layout

\end_deeper
\end_deeper
\end_body
\end_document
